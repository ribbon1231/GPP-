import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as T
from torchvision.models.detection import keypointrcnn_resnet50_fpn, KeypointRCNN_ResNet50_FPN_Weights
import numpy as np
from rembg import remove

# --- 1. ëª¨ë¸ ë¡œë”© (ìµœì´ˆ í•œ ë²ˆë§Œ ì‹¤í–‰) ---
@st.cache_resource
def load_model():
    weights = KeypointRCNN_ResNet50_FPN_Weights.DEFAULT
    model = keypointrcnn_resnet50_fpn(weights=weights, progress=False)
    model.eval()
    return model, weights.transforms()

model, transforms = load_model()

# --- 2. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ë“¤ ---
def get_person_pose(image_pil):
    """ì‚¬ëŒ ì´ë¯¸ì§€(PIL)ë¥¼ ë°›ì•„ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    image_tensor = transforms(image_pil)
    with torch.no_grad():
        output = model([image_tensor])
    
    # ê°€ì¥ í™•ë¥  ë†’ì€ ì‚¬ëŒì˜ í‚¤í¬ì¸íŠ¸, ì ìˆ˜ ì¶”ì¶œ
    scores = output[0]['scores'].detach().numpy()
    if len(scores) == 0:
        return None, None
        
    best_person_idx = np.argmax(scores)
    keypoints = output[0]['keypoints'][best_person_idx].detach().numpy()
    keypoints_scores = output[0]['keypoints_scores'][best_person_idx].detach().numpy()
    
    return keypoints, keypoints_scores

def overlay_clothing(person_img, clothing_img, keypoints):
    """ì‚¬ëŒ ì´ë¯¸ì§€ ìœ„ì— ì˜· ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” í•¨ìˆ˜"""
    # í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤: 5(ì™¼ìª½ì–´ê¹¨), 6(ì˜¤ë¥¸ìª½ì–´ê¹¨), 11(ì™¼ìª½ì—‰ë©ì´), 12(ì˜¤ë¥¸ìª½ì—‰ë©ì´)
    left_shoulder = keypoints[5][:2]
    right_shoulder = keypoints[6][:2]
    left_hip = keypoints[11][:2]
    right_hip = keypoints[12][:2]

    # 1. ì˜·ì˜ ë„ˆë¹„ ê³„ì‚°: ì–´ê¹¨ ë„ˆë¹„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
    shoulder_width = np.linalg.norm(left_shoulder - right_shoulder)
    clothing_width = int(shoulder_width * 1.9) # ì´ ìˆ«ìë¥¼ ì¡°ì ˆí•˜ë©´ ì˜·ì˜ 'ë„ˆë¹„'ê°€ ë°”ë€ë‹ˆë‹¤.

    # 2. ìƒì²´ ê¸¸ì´ ê³„ì‚°
    shoulder_center = (left_shoulder + right_shoulder) / 2
    hip_center = (left_hip + right_hip) / 2
    body_height = np.linalg.norm(shoulder_center - hip_center)
    
    # ëª¸ ë†’ì´ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€
    if body_height == 0:
        body_height = shoulder_width * 1.2 

    # ìƒì²´ ê¸¸ì´(body_height)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜·ì˜ ë†’ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    clothing_height = int(body_height * 1.5) # ì´ ìˆ«ìë¥¼ ì¡°ì ˆí•˜ë©´ ì˜·ì˜ 'ë†’ì´'ê°€ ë°”ë€ë‹ˆë‹¤.

    # 3. ì˜·ì˜ ìœ„ì¹˜(ì¤‘ì‹¬ì ) ê³„ì‚°
    center_x = int(shoulder_center[0])
    center_y = int(shoulder_center[1] + body_height * 0.5) 

    # 4. ì˜·ì˜ ê°ë„ ê³„ì‚°
    angle = np.degrees(np.arctan2(right_shoulder[1] - left_shoulder[1], right_shoulder[0] - left_shoulder[0]))

    # 5. ì˜· ì´ë¯¸ì§€ ë³€í™˜
    # ë°°ê²½ ì œê±°
    clothing_nobg = remove(clothing_img)
    
    # í¬ê¸° ì¡°ì ˆ (ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì ìš©)
    resized_clothing = clothing_nobg.resize((clothing_width, clothing_height))
    
    # ê°ë„ ì¡°ì ˆ (ë’¤ì§‘í˜ ë¬¸ì œ í•´ê²°)
    rotated_clothing = resized_clothing.rotate(-angle + 180, expand=True, resample=Image.BICUBIC)

    # 6. ì›ë³¸ ì´ë¯¸ì§€ì— ì˜· í•©ì„±
    result_img = person_img.copy()
    
    # ì˜·ì„ ë¶™ì—¬ë„£ì„ ìœ„ì¹˜ ê³„ì‚°
    paste_x = center_x - rotated_clothing.width // 2
    paste_y = center_y - rotated_clothing.height // 2
    
    # RGBA ì´ë¯¸ì§€ì˜ íˆ¬ëª…ë„ë¥¼ ë§ˆìŠ¤í¬ë¡œ ì‚¬ìš©í•˜ì—¬ ë¶™ì—¬ë„£ê¸°
    result_img.paste(rotated_clothing, (paste_x, paste_y), rotated_clothing)

    return result_img

# --- 3. Streamlit UI êµ¬ì„± ---
st.set_page_config(layout="wide")
st.title("ğŸ‘• AI ê°€ìƒ í”¼íŒ… (Virtual Try-On) ë°ëª¨")
st.write("---")
st.info("ì‚¬ëŒì˜ ìƒë°˜ì‹ ì´ ì˜ ë³´ì´ëŠ” ì‚¬ì§„ê³¼, ë°°ê²½ì´ ìˆëŠ” ì˜· ì‚¬ì§„ì„ ê°ê° ì—…ë¡œë“œ í•´ë³´ì„¸ìš”!")

col1, col2 = st.columns(2)

with col1:
    st.header("ğŸ‘¤ ì‚¬ëŒ ì‚¬ì§„ ì—…ë¡œë“œ")
    person_file = st.file_uploader("ì‚¬ëŒ ì‚¬ì§„ì„ ì„ íƒí•˜ì„¸ìš”.", type=['jpg', 'jpeg', 'png'])

with col2:
    st.header("ğŸ‘š ì˜· ì‚¬ì§„ ì—…ë¡œë“œ")
    clothing_file = st.file_uploader("ì˜· ì‚¬ì§„ì„ ì„ íƒí•˜ì„¸ìš”.", type=['jpg', 'jpeg', 'png'])


if person_file and clothing_file:
    person_img = Image.open(person_file).convert("RGB")
    clothing_img = Image.open(clothing_file).convert("RGBA") # RGBAë¡œ ì—´ì–´ì•¼ íˆ¬ëª…ë„ ì²˜ë¦¬ ê°€ëŠ¥

    st.write("---")
    st.header("â–¶ï¸ ì›ë³¸ ì´ë¯¸ì§€")
    c1, c2 = st.columns(2)
    with c1:
        st.image(person_img, caption="ì‚¬ëŒ ì›ë³¸", use_column_width=True)
    with c2:
        st.image(clothing_img, caption="ì˜· ì›ë³¸", use_column_width=True)
    
    if st.button("ê°€ìƒ í”¼íŒ… ì‹œì‘!", use_container_width=True):
        with st.spinner('AIê°€ ì‚¬ëŒì˜ í¬ì¦ˆë¥¼ ë¶„ì„í•˜ê³  ì˜·ì„ ì…íˆëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            # 1. í¬ì¦ˆ ì¶”ì •
            keypoints, scores = get_person_pose(person_img)
            
            if keypoints is None:
                st.error("ì‚¬ì§„ì—ì„œ ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ì§„ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")
            else:
                # 2. ì´ë¯¸ì§€ í•©ì„±
                final_image = overlay_clothing(person_img, clothing_img, keypoints)
                
                # 3. ê²°ê³¼ í‘œì‹œ
                st.write("---")
                st.header("âœ… í•©ì„± ê²°ê³¼")
                st.image(final_image, caption="AI ê°€ìƒ í”¼íŒ… ê²°ê³¼", use_column_width=True)